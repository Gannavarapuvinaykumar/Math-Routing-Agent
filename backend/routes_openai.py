from fastapi import APIRouter
import os
from openai import OpenAI
import asyncio

router = APIRouter()

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

@router.get("/openai/health")
async def check_openai_health():
    """Check if OpenAI API is available"""
    try:
        # Test API key by making a simple request
        response = await asyncio.to_thread(
            client.models.list
        )
        
        return {
            "status": "healthy",
            "available_models": ["gpt-4", "gpt-3.5-turbo", "gpt-4-turbo"],
            "openai_available": True
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "openai_available": False,
            "message": "Set OPENAI_API_KEY environment variable"
        }

@router.post("/openai/solve")
async def solve_with_openai(query: str, model: str = "gpt-4"):
    """Solve math problem using OpenAI"""
    try:
        prompt = f"""You are a math professor. Solve this step-by-step: {query}

Format your response as:
Answer: [final answer]
Steps:
1. [step 1]
2. [step 2]
3. [step 3]
...

Be clear and educational."""
        
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model=model,
            messages=[
                {"role": "system", "content": "You are an expert math professor who explains solutions clearly and step-by-step."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.1
        )
        
        ai_response = response.choices[0].message.content
        
        return {
            "answer": "Generated by AI",
            "steps": ai_response,
            "source": "OpenAI GPT",
            "model": model,
            "raw_response": ai_response
        }
    except Exception as e:
        return {
            "error": f"AI generation failed: {str(e)}",
            "message": "Make sure OPENAI_API_KEY is set and valid"
        }
